{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7962c31-7842-4478-a10b-4d5adab4473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6875c9f3-84a5-4132-95d9-c717ce47f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_for_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3185a7-c577-4fba-8fa2-dad1de267046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipe_id</th>\n",
       "      <th>install_year</th>\n",
       "      <th>material</th>\n",
       "      <th>diameter</th>\n",
       "      <th>env_dat_0</th>\n",
       "      <th>env_dat_1</th>\n",
       "      <th>env_dat_2</th>\n",
       "      <th>env_dat_3</th>\n",
       "      <th>env_dat_4</th>\n",
       "      <th>env_dat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>env_dat_136</th>\n",
       "      <th>env_dat_137</th>\n",
       "      <th>env_dat_138</th>\n",
       "      <th>env_dat_139</th>\n",
       "      <th>env_dat_140</th>\n",
       "      <th>env_dat_141</th>\n",
       "      <th>env_dat_142</th>\n",
       "      <th>env_dat_143</th>\n",
       "      <th>env_dat_144</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0000000000</td>\n",
       "      <td>1985</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>623.542175</td>\n",
       "      <td>18.052843</td>\n",
       "      <td>14.161422</td>\n",
       "      <td>10.268579</td>\n",
       "      <td>159.662827</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>438.628143</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3085.786865</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.311803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0000000001</td>\n",
       "      <td>1934</td>\n",
       "      <td>C</td>\n",
       "      <td>15.24</td>\n",
       "      <td>644.830017</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>13.830000</td>\n",
       "      <td>9.870000</td>\n",
       "      <td>257.001221</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>...</td>\n",
       "      <td>9.200573</td>\n",
       "      <td>0.304329</td>\n",
       "      <td>239.719299</td>\n",
       "      <td>32.571018</td>\n",
       "      <td>3188.292236</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.322161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0000000002</td>\n",
       "      <td>1904</td>\n",
       "      <td>C</td>\n",
       "      <td>20.32</td>\n",
       "      <td>604.570007</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>10.470000</td>\n",
       "      <td>225.165039</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>4.872639</td>\n",
       "      <td>0.182168</td>\n",
       "      <td>500.638367</td>\n",
       "      <td>28.978306</td>\n",
       "      <td>4542.257324</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.458972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0000000003</td>\n",
       "      <td>1979</td>\n",
       "      <td>D</td>\n",
       "      <td>15.24</td>\n",
       "      <td>573.424011</td>\n",
       "      <td>17.671381</td>\n",
       "      <td>14.132636</td>\n",
       "      <td>10.586646</td>\n",
       "      <td>170.244339</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>...</td>\n",
       "      <td>12.353504</td>\n",
       "      <td>0.480517</td>\n",
       "      <td>295.554504</td>\n",
       "      <td>41.983772</td>\n",
       "      <td>4521.720215</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0000000004</td>\n",
       "      <td>1987</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>583.429993</td>\n",
       "      <td>18.280001</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>10.420000</td>\n",
       "      <td>171.034073</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>...</td>\n",
       "      <td>25.052542</td>\n",
       "      <td>0.021532</td>\n",
       "      <td>778.687256</td>\n",
       "      <td>25.842377</td>\n",
       "      <td>4978.718262</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.503074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pipe_id  install_year material  diameter   env_dat_0  env_dat_1  \\\n",
       "0  P0000000000          1985        D     20.32  623.542175  18.052843   \n",
       "1  P0000000001          1934        C     15.24  644.830017  17.790001   \n",
       "2  P0000000002          1904        C     20.32  604.570007  18.219999   \n",
       "3  P0000000003          1979        D     15.24  573.424011  17.671381   \n",
       "4  P0000000004          1987        D     20.32  583.429993  18.280001   \n",
       "\n",
       "   env_dat_2  env_dat_3   env_dat_4  env_dat_5  ...  env_dat_136  env_dat_137  \\\n",
       "0  14.161422  10.268579  159.662827   0.010340  ...    20.000000     0.000038   \n",
       "1  13.830000   9.870000  257.001221   0.007786  ...     9.200573     0.304329   \n",
       "2  14.350000  10.470000  225.165039   0.014548  ...     4.872639     0.182168   \n",
       "3  14.132636  10.586646  170.244339   0.014938  ...    12.353504     0.480517   \n",
       "4  14.350000  10.420000  171.034073   0.025906  ...    25.052542     0.021532   \n",
       "\n",
       "   env_dat_138  env_dat_139  env_dat_140  env_dat_141  env_dat_142  \\\n",
       "0   438.628143    27.000000  3085.786865     0.002728     0.311803   \n",
       "1   239.719299    32.571018  3188.292236     0.003291     0.322161   \n",
       "2   500.638367    28.978306  4542.257324     0.002928     0.458972   \n",
       "3   295.554504    41.983772  4521.720215     0.004242     0.456897   \n",
       "4   778.687256    25.842377  4978.718262     0.002611     0.503074   \n",
       "\n",
       "   env_dat_143  env_dat_144  target  \n",
       "0          0.0          0.0       0  \n",
       "1          0.0          0.0       0  \n",
       "2          0.0          0.0       0  \n",
       "3          0.0          0.0       0  \n",
       "4          0.0          0.0       0  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e606c5f0-bf3e-45b9-9ec1-8b18505ccdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17db53fc-5091-43be-9f77-89e1aaad1b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4652dfda-ca17-44f2-8f70-a3f5f3b86f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56774, 149)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10092a98-aac8-468d-bce3-83b139185e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipe_id</th>\n",
       "      <th>install_year</th>\n",
       "      <th>material</th>\n",
       "      <th>diameter</th>\n",
       "      <th>env_dat_0</th>\n",
       "      <th>env_dat_1</th>\n",
       "      <th>env_dat_2</th>\n",
       "      <th>env_dat_3</th>\n",
       "      <th>env_dat_4</th>\n",
       "      <th>env_dat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>env_dat_135</th>\n",
       "      <th>env_dat_136</th>\n",
       "      <th>env_dat_137</th>\n",
       "      <th>env_dat_138</th>\n",
       "      <th>env_dat_139</th>\n",
       "      <th>env_dat_140</th>\n",
       "      <th>env_dat_141</th>\n",
       "      <th>env_dat_142</th>\n",
       "      <th>env_dat_143</th>\n",
       "      <th>env_dat_144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0000000000</td>\n",
       "      <td>1985</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>623.542175</td>\n",
       "      <td>18.052843</td>\n",
       "      <td>14.161422</td>\n",
       "      <td>10.268579</td>\n",
       "      <td>159.662827</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>...</td>\n",
       "      <td>554.479675</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>438.628143</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3085.786865</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.311803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0000000001</td>\n",
       "      <td>1934</td>\n",
       "      <td>C</td>\n",
       "      <td>15.24</td>\n",
       "      <td>644.830017</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>13.830000</td>\n",
       "      <td>9.870000</td>\n",
       "      <td>257.001221</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>...</td>\n",
       "      <td>276.357605</td>\n",
       "      <td>9.200573</td>\n",
       "      <td>0.304329</td>\n",
       "      <td>239.719299</td>\n",
       "      <td>32.571018</td>\n",
       "      <td>3188.292236</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.322161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0000000002</td>\n",
       "      <td>1904</td>\n",
       "      <td>C</td>\n",
       "      <td>20.32</td>\n",
       "      <td>604.570007</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>10.470000</td>\n",
       "      <td>225.165039</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>...</td>\n",
       "      <td>236.882950</td>\n",
       "      <td>4.872639</td>\n",
       "      <td>0.182168</td>\n",
       "      <td>500.638367</td>\n",
       "      <td>28.978306</td>\n",
       "      <td>4542.257324</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.458972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0000000003</td>\n",
       "      <td>1979</td>\n",
       "      <td>D</td>\n",
       "      <td>15.24</td>\n",
       "      <td>573.424011</td>\n",
       "      <td>17.671381</td>\n",
       "      <td>14.132636</td>\n",
       "      <td>10.586646</td>\n",
       "      <td>170.244339</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>...</td>\n",
       "      <td>321.886658</td>\n",
       "      <td>12.353504</td>\n",
       "      <td>0.480517</td>\n",
       "      <td>295.554504</td>\n",
       "      <td>41.983772</td>\n",
       "      <td>4521.720215</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0000000004</td>\n",
       "      <td>1987</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>583.429993</td>\n",
       "      <td>18.280001</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>10.420000</td>\n",
       "      <td>171.034073</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>...</td>\n",
       "      <td>758.841431</td>\n",
       "      <td>25.052542</td>\n",
       "      <td>0.021532</td>\n",
       "      <td>778.687256</td>\n",
       "      <td>25.842377</td>\n",
       "      <td>4978.718262</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.503074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56769</th>\n",
       "      <td>P0000055554</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>610.280029</td>\n",
       "      <td>18.280001</td>\n",
       "      <td>14.340000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>190.049469</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>...</td>\n",
       "      <td>396.748718</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.719997</td>\n",
       "      <td>170.973465</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2504.886719</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.253106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56770</th>\n",
       "      <td>P0000055555</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>610.280029</td>\n",
       "      <td>18.280001</td>\n",
       "      <td>14.340000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>190.049469</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>...</td>\n",
       "      <td>396.748718</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.719997</td>\n",
       "      <td>170.973465</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2504.886719</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.253106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56771</th>\n",
       "      <td>P0000055556</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>610.280029</td>\n",
       "      <td>18.280001</td>\n",
       "      <td>14.340000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>190.049469</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>...</td>\n",
       "      <td>396.748718</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.719997</td>\n",
       "      <td>170.973465</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2504.886719</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.253106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56772</th>\n",
       "      <td>P0000055557</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>610.280029</td>\n",
       "      <td>18.280001</td>\n",
       "      <td>14.340000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>190.049469</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>...</td>\n",
       "      <td>396.748718</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.719997</td>\n",
       "      <td>170.973465</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2504.886719</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.253106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56773</th>\n",
       "      <td>P0000055558</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>610.280029</td>\n",
       "      <td>18.280001</td>\n",
       "      <td>14.340000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>190.049469</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>...</td>\n",
       "      <td>396.748718</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.719997</td>\n",
       "      <td>170.973465</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2504.886719</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.253106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55559 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pipe_id  install_year material  diameter   env_dat_0  env_dat_1  \\\n",
       "0      P0000000000          1985        D     20.32  623.542175  18.052843   \n",
       "1      P0000000001          1934        C     15.24  644.830017  17.790001   \n",
       "2      P0000000002          1904        C     20.32  604.570007  18.219999   \n",
       "3      P0000000003          1979        D     15.24  573.424011  17.671381   \n",
       "4      P0000000004          1987        D     20.32  583.429993  18.280001   \n",
       "...            ...           ...      ...       ...         ...        ...   \n",
       "56769  P0000055554          2016        D     20.32  610.280029  18.280001   \n",
       "56770  P0000055555          2016        D     20.32  610.280029  18.280001   \n",
       "56771  P0000055556          2016        D     20.32  610.280029  18.280001   \n",
       "56772  P0000055557          2016        D     20.32  610.280029  18.280001   \n",
       "56773  P0000055558          2016        D     20.32  610.280029  18.280001   \n",
       "\n",
       "       env_dat_2  env_dat_3   env_dat_4  env_dat_5  ...  env_dat_135  \\\n",
       "0      14.161422  10.268579  159.662827   0.010340  ...   554.479675   \n",
       "1      13.830000   9.870000  257.001221   0.007786  ...   276.357605   \n",
       "2      14.350000  10.470000  225.165039   0.014548  ...   236.882950   \n",
       "3      14.132636  10.586646  170.244339   0.014938  ...   321.886658   \n",
       "4      14.350000  10.420000  171.034073   0.025906  ...   758.841431   \n",
       "...          ...        ...         ...        ...  ...          ...   \n",
       "56769  14.340000  10.400000  190.049469   0.010628  ...   396.748718   \n",
       "56770  14.340000  10.400000  190.049469   0.010628  ...   396.748718   \n",
       "56771  14.340000  10.400000  190.049469   0.010628  ...   396.748718   \n",
       "56772  14.340000  10.400000  190.049469   0.010628  ...   396.748718   \n",
       "56773  14.340000  10.400000  190.049469   0.010628  ...   396.748718   \n",
       "\n",
       "       env_dat_136  env_dat_137  env_dat_138  env_dat_139  env_dat_140  \\\n",
       "0        20.000000     0.000038   438.628143    27.000000  3085.786865   \n",
       "1         9.200573     0.304329   239.719299    32.571018  3188.292236   \n",
       "2         4.872639     0.182168   500.638367    28.978306  4542.257324   \n",
       "3        12.353504     0.480517   295.554504    41.983772  4521.720215   \n",
       "4        25.052542     0.021532   778.687256    25.842377  4978.718262   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "56769     6.000000     0.719997   170.973465    26.000000  2504.886719   \n",
       "56770     6.000000     0.719997   170.973465    26.000000  2504.886719   \n",
       "56771     6.000000     0.719997   170.973465    26.000000  2504.886719   \n",
       "56772     6.000000     0.719997   170.973465    26.000000  2504.886719   \n",
       "56773     6.000000     0.719997   170.973465    26.000000  2504.886719   \n",
       "\n",
       "       env_dat_141  env_dat_142  env_dat_143  env_dat_144  \n",
       "0         0.002728     0.311803          0.0          0.0  \n",
       "1         0.003291     0.322161          0.0          0.0  \n",
       "2         0.002928     0.458972          0.0          0.0  \n",
       "3         0.004242     0.456897          0.0          0.0  \n",
       "4         0.002611     0.503074          0.0          0.0  \n",
       "...            ...          ...          ...          ...  \n",
       "56769     0.002627     0.253106          0.0          0.0  \n",
       "56770     0.002627     0.253106          0.0          0.0  \n",
       "56771     0.002627     0.253106          0.0          0.0  \n",
       "56772     0.002627     0.253106          0.0          0.0  \n",
       "56773     0.002627     0.253106          0.0          0.0  \n",
       "\n",
       "[55559 rows x 149 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop_duplicates(keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c931d8a4-b9b4-4d96-b682-4af4e8a6e10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipe_id</th>\n",
       "      <th>install_year</th>\n",
       "      <th>material</th>\n",
       "      <th>diameter</th>\n",
       "      <th>env_dat_0</th>\n",
       "      <th>env_dat_1</th>\n",
       "      <th>env_dat_2</th>\n",
       "      <th>env_dat_3</th>\n",
       "      <th>env_dat_4</th>\n",
       "      <th>env_dat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>env_dat_135</th>\n",
       "      <th>env_dat_136</th>\n",
       "      <th>env_dat_137</th>\n",
       "      <th>env_dat_138</th>\n",
       "      <th>env_dat_139</th>\n",
       "      <th>env_dat_140</th>\n",
       "      <th>env_dat_141</th>\n",
       "      <th>env_dat_142</th>\n",
       "      <th>env_dat_143</th>\n",
       "      <th>env_dat_144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P0000000009</td>\n",
       "      <td>1967</td>\n",
       "      <td>C</td>\n",
       "      <td>40.64</td>\n",
       "      <td>621.520020</td>\n",
       "      <td>18.389999</td>\n",
       "      <td>14.380000</td>\n",
       "      <td>10.370000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.491898</td>\n",
       "      <td>120.759766</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>835.561951</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.084429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>P0000000119</td>\n",
       "      <td>1934</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>635.059998</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>13.850000</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>213.618225</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>...</td>\n",
       "      <td>202.541885</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.092864</td>\n",
       "      <td>153.147385</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3679.603027</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.371805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>P0000000452</td>\n",
       "      <td>1989</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>615.719971</td>\n",
       "      <td>17.959999</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>34.133255</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>...</td>\n",
       "      <td>143.234604</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.374597</td>\n",
       "      <td>463.910614</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2938.658936</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.296937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>P0000000515</td>\n",
       "      <td>1933</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632.330017</td>\n",
       "      <td>18.520000</td>\n",
       "      <td>14.410000</td>\n",
       "      <td>10.290000</td>\n",
       "      <td>204.133987</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>...</td>\n",
       "      <td>299.100677</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.401415</td>\n",
       "      <td>239.565048</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2849.369141</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.287914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>P0000000666</td>\n",
       "      <td>1934</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>635.059998</td>\n",
       "      <td>17.490000</td>\n",
       "      <td>13.850000</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>89.535225</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>...</td>\n",
       "      <td>344.991058</td>\n",
       "      <td>9.956148</td>\n",
       "      <td>3.996830</td>\n",
       "      <td>1200.711426</td>\n",
       "      <td>19.361086</td>\n",
       "      <td>2969.813477</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.300085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56366</th>\n",
       "      <td>P0000055151</td>\n",
       "      <td>2002</td>\n",
       "      <td>D</td>\n",
       "      <td>30.48</td>\n",
       "      <td>552.996704</td>\n",
       "      <td>17.968988</td>\n",
       "      <td>14.361272</td>\n",
       "      <td>10.750011</td>\n",
       "      <td>11.477139</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>...</td>\n",
       "      <td>854.363037</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56558</th>\n",
       "      <td>P0000055343</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>30.48</td>\n",
       "      <td>538.739990</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>10.810000</td>\n",
       "      <td>243.621994</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56559</th>\n",
       "      <td>P0000055344</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>538.739990</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>10.810000</td>\n",
       "      <td>243.621994</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56560</th>\n",
       "      <td>P0000055345</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "      <td>538.739990</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>10.810000</td>\n",
       "      <td>243.621994</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56561</th>\n",
       "      <td>P0000055346</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>30.48</td>\n",
       "      <td>538.739990</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>10.810000</td>\n",
       "      <td>243.621994</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pipe_id  install_year material  diameter   env_dat_0  env_dat_1  \\\n",
       "9      P0000000009          1967        C     40.64  621.520020  18.389999   \n",
       "121    P0000000119          1934        C       NaN  635.059998  17.490000   \n",
       "454    P0000000452          1989        D       NaN  615.719971  17.959999   \n",
       "519    P0000000515          1933        C       NaN  632.330017  18.520000   \n",
       "672    P0000000666          1934        C       NaN  635.059998  17.490000   \n",
       "...            ...           ...      ...       ...         ...        ...   \n",
       "56366  P0000055151          2002        D     30.48  552.996704  17.968988   \n",
       "56558  P0000055343          2016        D     30.48  538.739990  18.580000   \n",
       "56559  P0000055344          2016        D     20.32  538.739990  18.580000   \n",
       "56560  P0000055345          2016        D     20.32  538.739990  18.580000   \n",
       "56561  P0000055346          2016        D     30.48  538.739990  18.580000   \n",
       "\n",
       "       env_dat_2  env_dat_3   env_dat_4  env_dat_5  ...  env_dat_135  \\\n",
       "9      14.380000  10.370000  122.000000   0.002382  ...          NaN   \n",
       "121    13.850000  10.210000  213.618225   0.010895  ...   202.541885   \n",
       "454    14.090000  10.210000   34.133255   0.002201  ...   143.234604   \n",
       "519    14.410000  10.290000  204.133987   0.011457  ...   299.100677   \n",
       "672    13.850000  10.210000   89.535225   0.004574  ...   344.991058   \n",
       "...          ...        ...         ...        ...  ...          ...   \n",
       "56366  14.361272  10.750011   11.477139   0.000139  ...   854.363037   \n",
       "56558  14.700000  10.810000  243.621994   0.002717  ...          NaN   \n",
       "56559  14.700000  10.810000  243.621994   0.002717  ...          NaN   \n",
       "56560  14.700000  10.810000  243.621994   0.002717  ...          NaN   \n",
       "56561  14.700000  10.810000  243.621994   0.002717  ...          NaN   \n",
       "\n",
       "       env_dat_136  env_dat_137  env_dat_138  env_dat_139  env_dat_140  \\\n",
       "9              NaN     8.491898   120.759766    15.000000   835.561951   \n",
       "121       2.000000     0.092864   153.147385    41.000000  3679.603027   \n",
       "454       6.000000     5.374597   463.910614    13.000000  2938.658936   \n",
       "519       9.000000     1.401415   239.565048    31.000000  2849.369141   \n",
       "672       9.956148     3.996830  1200.711426    19.361086  2969.813477   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "56366    29.000000          NaN          NaN          NaN          NaN   \n",
       "56558          NaN          NaN          NaN          NaN          NaN   \n",
       "56559          NaN          NaN          NaN          NaN          NaN   \n",
       "56560          NaN          NaN          NaN          NaN          NaN   \n",
       "56561          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       env_dat_141  env_dat_142  env_dat_143  env_dat_144  \n",
       "9         0.001516     0.084429          NaN          NaN  \n",
       "121       0.004143     0.371805          0.0          0.0  \n",
       "454       0.001314     0.296937          0.0          0.0  \n",
       "519       0.003132     0.287914          0.0          0.0  \n",
       "672       0.001956     0.300085          0.0          0.0  \n",
       "...            ...          ...          ...          ...  \n",
       "56366          NaN          NaN          0.0          0.0  \n",
       "56558          NaN          NaN          NaN          NaN  \n",
       "56559          NaN          NaN          NaN          NaN  \n",
       "56560          NaN          NaN          NaN          NaN  \n",
       "56561          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[824 rows x 149 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb95e15d-2170-467e-9384-92cd3131067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipe_id</th>\n",
       "      <th>install_year</th>\n",
       "      <th>material</th>\n",
       "      <th>diameter</th>\n",
       "      <th>env_dat_0</th>\n",
       "      <th>env_dat_1</th>\n",
       "      <th>env_dat_2</th>\n",
       "      <th>env_dat_3</th>\n",
       "      <th>env_dat_4</th>\n",
       "      <th>env_dat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>env_dat_135</th>\n",
       "      <th>env_dat_136</th>\n",
       "      <th>env_dat_137</th>\n",
       "      <th>env_dat_138</th>\n",
       "      <th>env_dat_139</th>\n",
       "      <th>env_dat_140</th>\n",
       "      <th>env_dat_141</th>\n",
       "      <th>env_dat_142</th>\n",
       "      <th>env_dat_143</th>\n",
       "      <th>env_dat_144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pipe_id, install_year, material, diameter, env_dat_0, env_dat_1, env_dat_2, env_dat_3, env_dat_4, env_dat_5, env_dat_6, env_dat_7, env_dat_8, env_dat_9, env_dat_10, env_dat_11, env_dat_12, env_dat_13, env_dat_14, env_dat_15, env_dat_16, env_dat_17, env_dat_18, env_dat_19, env_dat_20, env_dat_21, env_dat_22, env_dat_23, env_dat_24, env_dat_25, env_dat_26, env_dat_27, env_dat_28, env_dat_29, env_dat_30, env_dat_31, env_dat_32, env_dat_33, env_dat_34, env_dat_35, env_dat_36, env_dat_37, env_dat_38, env_dat_39, env_dat_40, env_dat_41, env_dat_42, env_dat_43, env_dat_44, env_dat_45, env_dat_46, env_dat_47, env_dat_48, env_dat_49, env_dat_50, env_dat_51, env_dat_52, env_dat_53, env_dat_54, env_dat_55, env_dat_56, env_dat_57, env_dat_58, env_dat_59, env_dat_60, env_dat_61, env_dat_62, env_dat_63, env_dat_64, env_dat_65, env_dat_66, env_dat_67, env_dat_68, env_dat_69, env_dat_70, env_dat_71, env_dat_72, env_dat_73, env_dat_74, env_dat_75, env_dat_76, env_dat_77, env_dat_78, env_dat_79, env_dat_80, env_dat_81, env_dat_82, env_dat_83, env_dat_84, env_dat_85, env_dat_86, env_dat_87, env_dat_88, env_dat_89, env_dat_90, env_dat_91, env_dat_92, env_dat_93, env_dat_94, env_dat_95, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 149 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['material'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31a4554-4fc7-4b64-8fad-f4ad3aad4850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipe_id</th>\n",
       "      <th>install_year</th>\n",
       "      <th>material</th>\n",
       "      <th>diameter</th>\n",
       "      <th>env_dat_0</th>\n",
       "      <th>env_dat_1</th>\n",
       "      <th>env_dat_2</th>\n",
       "      <th>env_dat_3</th>\n",
       "      <th>env_dat_4</th>\n",
       "      <th>env_dat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>env_dat_135</th>\n",
       "      <th>env_dat_136</th>\n",
       "      <th>env_dat_137</th>\n",
       "      <th>env_dat_138</th>\n",
       "      <th>env_dat_139</th>\n",
       "      <th>env_dat_140</th>\n",
       "      <th>env_dat_141</th>\n",
       "      <th>env_dat_142</th>\n",
       "      <th>env_dat_143</th>\n",
       "      <th>env_dat_144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pipe_id, install_year, material, diameter, env_dat_0, env_dat_1, env_dat_2, env_dat_3, env_dat_4, env_dat_5, env_dat_6, env_dat_7, env_dat_8, env_dat_9, env_dat_10, env_dat_11, env_dat_12, env_dat_13, env_dat_14, env_dat_15, env_dat_16, env_dat_17, env_dat_18, env_dat_19, env_dat_20, env_dat_21, env_dat_22, env_dat_23, env_dat_24, env_dat_25, env_dat_26, env_dat_27, env_dat_28, env_dat_29, env_dat_30, env_dat_31, env_dat_32, env_dat_33, env_dat_34, env_dat_35, env_dat_36, env_dat_37, env_dat_38, env_dat_39, env_dat_40, env_dat_41, env_dat_42, env_dat_43, env_dat_44, env_dat_45, env_dat_46, env_dat_47, env_dat_48, env_dat_49, env_dat_50, env_dat_51, env_dat_52, env_dat_53, env_dat_54, env_dat_55, env_dat_56, env_dat_57, env_dat_58, env_dat_59, env_dat_60, env_dat_61, env_dat_62, env_dat_63, env_dat_64, env_dat_65, env_dat_66, env_dat_67, env_dat_68, env_dat_69, env_dat_70, env_dat_71, env_dat_72, env_dat_73, env_dat_74, env_dat_75, env_dat_76, env_dat_77, env_dat_78, env_dat_79, env_dat_80, env_dat_81, env_dat_82, env_dat_83, env_dat_84, env_dat_85, env_dat_86, env_dat_87, env_dat_88, env_dat_89, env_dat_90, env_dat_91, env_dat_92, env_dat_93, env_dat_94, env_dat_95, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 149 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['install_year'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0d67bf-f6f7-4ead-8968-56cd5ca7a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "env_dat_0       623.542175\n",
       "env_dat_1        18.052843\n",
       "env_dat_2        14.161422\n",
       "env_dat_3        10.268579\n",
       "env_dat_4       159.662827\n",
       "                  ...     \n",
       "env_dat_140    3085.786865\n",
       "env_dat_141       0.002728\n",
       "env_dat_142       0.311803\n",
       "env_dat_143            0.0\n",
       "env_dat_144            0.0\n",
       "Name: 0, Length: 145, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80513789-e905-4f84-98e4-a261243645c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipe_id</th>\n",
       "      <th>install_year</th>\n",
       "      <th>material</th>\n",
       "      <th>diameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0000000000</td>\n",
       "      <td>1985</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0000000001</td>\n",
       "      <td>1934</td>\n",
       "      <td>C</td>\n",
       "      <td>15.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0000000002</td>\n",
       "      <td>1904</td>\n",
       "      <td>C</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0000000003</td>\n",
       "      <td>1979</td>\n",
       "      <td>D</td>\n",
       "      <td>15.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0000000004</td>\n",
       "      <td>1987</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56769</th>\n",
       "      <td>P0000055554</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56770</th>\n",
       "      <td>P0000055555</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56771</th>\n",
       "      <td>P0000055556</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56772</th>\n",
       "      <td>P0000055557</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56773</th>\n",
       "      <td>P0000055558</td>\n",
       "      <td>2016</td>\n",
       "      <td>D</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56774 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pipe_id  install_year material  diameter\n",
       "0      P0000000000          1985        D     20.32\n",
       "1      P0000000001          1934        C     15.24\n",
       "2      P0000000002          1904        C     20.32\n",
       "3      P0000000003          1979        D     15.24\n",
       "4      P0000000004          1987        D     20.32\n",
       "...            ...           ...      ...       ...\n",
       "56769  P0000055554          2016        D     20.32\n",
       "56770  P0000055555          2016        D     20.32\n",
       "56771  P0000055556          2016        D     20.32\n",
       "56772  P0000055557          2016        D     20.32\n",
       "56773  P0000055558          2016        D     20.32\n",
       "\n",
       "[56774 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "405aca9c-75cc-4a1f-8703-988c3a9ba017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2d5277-f7b0-454f-a28b-f51976040225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "242fea19-9206-4421-8351-64fa628cdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31a80826-ea3d-41e5-986a-3f7e23aca5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56774, 148)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a60f58d-5c25-430c-a1c1-c1dd807f1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d92acddd-ccd4-424e-945f-a22a2f0b9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "\n",
    "ModelsPerformance = {}\n",
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
    "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
    "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "#     hamLoss = hamming_loss(test_labels, predictions)\n",
    "    print(\"------\" + modelName + \" Model Metrics-----\")\n",
    "    print(\"Accuracy: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
    "          .format(accuracy, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
    "    ModelsPerformance[modelName] = micro_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c9d51-91de-491d-943e-9a74ca3162c7",
   "metadata": {},
   "source": [
    "## Random Forrest\n",
    "\n",
    "Random forests provide an improvement over bagged trees by way of a small tweak that decorrelates the trees. As in bagging, we build a number of decision trees on bootstrapped training samples. But when building these decision trees, each time a split in a tree is considered, a random sample of m predictors is chosen as split candidates from the full set of p predictors. The split is allowed to use only one of those m predictors. A fresh sample of √m predictors is taken at each split, and typically we choose m ≈ p—that is, the number of predictors considered at each split is approximately equal to the square root of the total number of predictors\n",
    "\n",
    "In other words, in building a random forest, at each split in the tree, the algorithm is not even allowed to consider a majority of the available predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ab9e19e-3a54-4b26-a818-2a32b3d2efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Random Forest Model Metrics-----\n",
      "Accuracy: 0.9383\n",
      "Precision:\n",
      "  - Macro: 0.6791\n",
      "  - Micro: 0.9383\n",
      "Recall:\n",
      "  - Macro: 0.6016\n",
      "  - Micro: 0.9383\n",
      "F1-measure:\n",
      "  - Macro: 0.6273\n",
      "  - Micro: 0.9383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfClassifier = RandomForestClassifier(n_jobs=-1)\n",
    "rfClassifier.fit(X_train, y_train)\n",
    "rfPreds = rfClassifier.predict(X_test)\n",
    "metricsReport(\"Random Forest\", y_test, rfPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b31c0d-9efb-4e2d-aa0d-4947ab28e70d",
   "metadata": {},
   "source": [
    "## k-nearest neighbors algorithm (kNN)\n",
    "\n",
    "is a non-parametric technique used for classification. Given a test document x, the KNN algorithm finds the k nearest neighbors of x among all the documents in the training set, and scores the category candidates based the class of k neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c9dab3e-9c56-4519-ba91-f76e75aba16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------knn Model Metrics-----\n",
      "Accuracy: 0.9373\n",
      "Precision:\n",
      "  - Macro: 0.6240\n",
      "  - Micro: 0.9373\n",
      "Recall:\n",
      "  - Macro: 0.5402\n",
      "  - Micro: 0.9373\n",
      "F1-measure:\n",
      "  - Macro: 0.5548\n",
      "  - Micro: 0.9373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "knnClf = KNeighborsClassifier()\n",
    "\n",
    "knnClf.fit(X_train, y_train)\n",
    "knnPredictions = knnClf.predict(X_test)\n",
    "metricsReport(\"knn\", y_test, knnPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7a8c5-4ef1-43f6-8239-7a6ae14f6be5",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "Tree-based methods are simple and useful for interpretation. A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7727186-036b-414b-8bd0-9ad62c505024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Decision Tree Model Metrics-----\n",
      "Accuracy: 0.9114\n",
      "Precision:\n",
      "  - Macro: 0.5915\n",
      "  - Micro: 0.9114\n",
      "Recall:\n",
      "  - Macro: 0.5986\n",
      "  - Micro: 0.9114\n",
      "F1-measure:\n",
      "  - Macro: 0.5948\n",
      "  - Micro: 0.9114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtClassifier = DecisionTreeClassifier()\n",
    "dtClassifier.fit(X_train, y_train)\n",
    "dtPreds = dtClassifier.predict(X_test)\n",
    "metricsReport(\"Decision Tree\", y_test, dtPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae88dc7-7451-42ab-a05d-71381ffe08a7",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "The decision trees suffer from high variance.\n",
    "This means that if we split the training data into two parts at random, and fit a decision tree to both halves, the results that we get could be quite different.\n",
    "Bootstrap aggregation, or bagging, is a general-purpose procedure for reducing the variance of a statistical learning method; we introduce it here because it is particularly useful and frequently used in the context of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93c13152-c50c-4c42-8ec5-af59f99285bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Bagging Model Metrics-----\n",
      "Accuracy: 0.9398\n",
      "Precision:\n",
      "  - Macro: 0.6946\n",
      "  - Micro: 0.9398\n",
      "Recall:\n",
      "  - Macro: 0.6180\n",
      "  - Micro: 0.9398\n",
      "F1-measure:\n",
      "  - Macro: 0.6450\n",
      "  - Micro: 0.9398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "y_test\n",
    "bagClassifier = OneVsRestClassifier(BaggingClassifier(n_jobs=-1))\n",
    "bagClassifier.fit(X_train, y_train)\n",
    "bagPreds = bagClassifier.predict(X_test)\n",
    "metricsReport(\"Bagging\", y_test, bagPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c414963-f405-49dd-a094-d65d4236071e",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Recall that bagging involves creating multiple copies of the original train- ing data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predic- tive model. Notably, each tree is built on a bootstrap data set, independent of the other trees. Boosting works in a similar way, except that the trees are grown sequentially: each tree is grown using information from previously grown trees. Boosting does not involve bootstrap sampling; instead each tree is fit on a modified version of the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ab35a28-6c16-4c4b-a2e5-4b033ce9a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Boosting Model Metrics-----\n",
      "Accuracy: 0.9442\n",
      "Precision:\n",
      "  - Macro: 0.7194\n",
      "  - Micro: 0.9442\n",
      "Recall:\n",
      "  - Macro: 0.5230\n",
      "  - Micro: 0.9442\n",
      "F1-measure:\n",
      "  - Macro: 0.5301\n",
      "  - Micro: 0.9442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "boostClassifier = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "boostClassifier.fit(X_train, y_train)\n",
    "boostPreds = boostClassifier.predict(X_test)\n",
    "metricsReport(\"Boosting\", y_test, boostPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb3ea12-399a-4953-be08-a91179c94f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------GaussianNB Model Metrics-----\n",
      "Accuracy: 0.4881\n",
      "Precision:\n",
      "  - Macro: 0.5216\n",
      "  - Micro: 0.4881\n",
      "Recall:\n",
      "  - Macro: 0.6018\n",
      "  - Micro: 0.4881\n",
      "F1-measure:\n",
      "  - Macro: 0.3866\n",
      "  - Micro: 0.4881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nbClassifier = OneVsRestClassifier(GaussianNB())\n",
    "nbClassifier.fit(X_train, y_train)\n",
    "\n",
    "nbPreds = nbClassifier.predict(X_test)\n",
    "metricsReport(\"GaussianNB\", y_test, nbPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59938d-7a0d-42b5-af9e-b4dfd56d62d5",
   "metadata": {},
   "source": [
    "## Support Vector Machine (Linear SVC)\n",
    "\n",
    "Support Vector Machine (SVM), an approach for classification that was developed in the computer science community in the 1990s and that has grown in popularity since then.\n",
    "SVMs have been shown to perform well in a variety of settings, and are often considered one of the best “out of the box” classifiers.\n",
    "The support vector machine is a generalization of a simple and intuitive classifier called the maximal margin classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c874da4-86c1-4321-90d5-a8c2ce8c6176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SVC Sq. Hinge Loss Model Metrics-----\n",
      "Accuracy: 0.9442\n",
      "Precision:\n",
      "  - Macro: 0.4721\n",
      "  - Micro: 0.9442\n",
      "Recall:\n",
      "  - Macro: 0.5000\n",
      "  - Micro: 0.9442\n",
      "F1-measure:\n",
      "  - Macro: 0.4856\n",
      "  - Micro: 0.9442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svmClassifier = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "svmClassifier.fit(X_train, y_train)\n",
    "svmPreds = svmClassifier.predict(X_test)\n",
    "metricsReport(\"SVC Sq. Hinge Loss\", y_test, svmPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7b054-0c4a-4faa-a410-9108caa05f81",
   "metadata": {},
   "source": [
    "## Comparison on different models based on their Micro-F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bdee4b5-926d-479a-8bde-13f701aa2c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model Name           | Micro-F1 Score\n",
      "-------------------------------------------\n",
      "  Random Forest        | 0.938265081461911\n",
      "-------------------------------------------\n",
      "  knn                  | 0.937296345222369\n",
      "-------------------------------------------\n",
      "  Decision Tree        | 0.911404667547336\n",
      "-------------------------------------------\n",
      "  Bagging              | 0.9397622192866578\n",
      "-------------------------------------------\n",
      "  Boosting             | 0.9441655658300309\n",
      "-------------------------------------------\n",
      "  GaussianNB           | 0.4880669308674593\n",
      "-------------------------------------------\n",
      "  SVC Sq. Hinge Loss   | 0.9441655658300309\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"  Model Name \" + \" \"*10 + \"| Micro-F1 Score\")\n",
    "print(\"-------------------------------------------\")\n",
    "for key, value in ModelsPerformance.items():\n",
    "    print(\"  \" + key, \" \"*(20-len(key)) + \"|\", value)\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00b81810-092f-497b-97e3-eeb76d70de06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53630, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"target\"]==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1453e5-727a-4213-b438-2b06353c4225",
   "metadata": {},
   "source": [
    "## The Data imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "681cc965-3be4-4fa1-a4bf-1f617f562d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be7dc651-e4eb-438a-8f20-42ddc349a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])\n",
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42dd9040-0b18-4de2-a28a-1f00195ffc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 53630, 1: 3144})\n"
     ]
    }
   ],
   "source": [
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4130cf4-8e56-46a0-9e72-9218596fac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 10726, 1: 5363})\n"
     ]
    }
   ],
   "source": [
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_all, y = pipeline.fit_resample(X_all, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e159906f-95ed-44a5-8282-84a692c3f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.778\n"
     ]
    }
   ],
   "source": [
    "# decision tree evaluated on imbalanced dataset\n",
    "from numpy import mean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# define model\n",
    "model = DecisionTreeClassifier()\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X_all, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75a817be-f207-4e9f-adec-63aa4ae3c1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.701\n"
     ]
    }
   ],
   "source": [
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])\n",
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)\n",
    "# define pipeline\n",
    "steps = [('over', SMOTE()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X_all, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd96a31-5adb-4190-928a-304650397a90",
   "metadata": {},
   "source": [
    "As mentioned in the paper, it is believed that SMOTE performs better when combined with undersampling of the majority class, such as random undersampling.\n",
    "\n",
    "I achieve this by simply adding a RandomUnderSampler step to the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5823305f-0450-4615-8f39-498d024e4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])\n",
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)\n",
    "# define pipeline\n",
    "model = DecisionTreeClassifier()\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c491ca1-d44b-4028-93a9-5a6fb94738cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.712\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X_all, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bac58d-4d74-4b60-a35e-c3caa5075d19",
   "metadata": {},
   "source": [
    "I can explore testing different ratios of the minority class and majority class (e.g. changing the sampling_strategy argument) to see if a further lift in performance is possible.\n",
    "\n",
    "Another area to explore would be to test different values of the k-nearest neighbors selected in the SMOTE procedure when each new synthetic example is created. The default is k=5, although larger or smaller values will influence the types of examples created, and in turn, may impact the performance of the model.\n",
    "\n",
    "For example, I can grid search a range of values of k, such as values from 1 to 7, and evaluate the pipeline for each value.\n",
    "\n",
    "Running this will perform SMOTE oversampling with different k values for the KNN used in the procedure, followed by random undersampling and fitting a decision tree on the resulting training dataset.\n",
    "\n",
    "The mean ROC AUC is reported for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb783735-0fc7-4639-b961-48d46075eda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=1, Mean ROC AUC: 0.710\n",
      "> k=2, Mean ROC AUC: 0.710\n",
      "> k=3, Mean ROC AUC: 0.712\n",
      "> k=4, Mean ROC AUC: 0.712\n",
      "> k=5, Mean ROC AUC: 0.712\n",
      "> k=6, Mean ROC AUC: 0.711\n",
      "> k=7, Mean ROC AUC: 0.713\n"
     ]
    }
   ],
   "source": [
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])\n",
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)\n",
    "# values to evaluate\n",
    "k_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "for k in k_values:\n",
    "    # define pipeline\n",
    "    model = DecisionTreeClassifier()\n",
    "    over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    steps = [('over', over), ('under', under), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X_all, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    score = mean(scores)\n",
    "    print('> k=%d, Mean ROC AUC: %.3f' % (k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabccbc-b4fa-47f0-80f9-232a04352c5f",
   "metadata": {},
   "source": [
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision.\n",
    "Consider running the example a few times and compare the average outcome.\n",
    "In this case, the results suggest that a k=7 might be good with a ROC AUC of about 0.713\n",
    "\n",
    "This highlights that both the amount of oversampling and undersampling performed (sampling_strategy argument) and the number of datapoints selected from which a partner is chosen to create a synthetic example (k_neighbors) may be important parameters to select and tune for my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abcab2e-d251-4762-ab18-c2d311f8a381",
   "metadata": {},
   "source": [
    "## SMOTE With Selective Synthetic Sample Generation\n",
    "\n",
    "I can be selective about the datapoints in the minority class that are oversampled using SMOTE.\n",
    "\n",
    "In this section, I will review some extensions to SMOTE that are more selective regarding the datapoints from the minority class that provide the basis for generating new synthetic datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f9e07-7c30-4701-9d17-3d308b96f545",
   "metadata": {},
   "source": [
    "## Borderline-SMOTE\n",
    "A popular extension to SMOTE involves selecting those instances of the minority class that are misclassified, such as with a k-nearest neighbor classification model.\n",
    "\n",
    "I can then oversample just those difficult instances, providing more resolution only where it may be required.\n",
    "\n",
    ">The examples on the borderline and the ones nearby […] are more apt to be misclassified than the ones far from the borderline, and thus more important for classification.\n",
    "[ Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning, 2005.]\n",
    "\n",
    "These datapoints that are misclassified are likely ambiguous and in a region of the edge or border of decision boundary where class membership may overlap.\n",
    "As such, this modified to SMOTE is called Borderline-SMOTE and was proposed by Hui Han, et al. in their 2005 paper titled “Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6e78ddb-48ac-4a29-8c39-7110c9c7f334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.945\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])\n",
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)\n",
    "\n",
    "# transform the dataset\n",
    "oversample = BorderlineSMOTE()\n",
    "X_all, y = oversample.fit_resample(X_all, y)\n",
    "# define model and evaluate it\n",
    "model = DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X_all, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0588f-c6db-4c40-8ec3-7a5427e87edc",
   "metadata": {},
   "source": [
    "## Borderline-SMOTE SVM\n",
    "Hien Nguyen, et al. suggest using an alternative of Borderline-SMOTE where an SVM algorithm is used instead of a KNN to identify misclassified datapoints on the decision boundary.\n",
    "\n",
    "Their approach is summarized in the 2009 paper titled “Borderline Over-sampling For Imbalanced Data Classification.”\n",
    "An SVM is used to locate the decision boundary defined by the support vectors and datapoints in the minority class that close to the support vectors become the focus for generating synthetic datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c70a008d-5dc0-46c2-8024-bd9ec670c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.934\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])\n",
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)\n",
    "\n",
    "# transform the dataset\n",
    "oversample = SVMSMOTE()\n",
    "X_all, y = oversample.fit_resample(X_all, y)\n",
    "\n",
    "# define model and evaluate it\n",
    "model = DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X_all, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afcab4-a787-4dce-83d4-101abdba181c",
   "metadata": {},
   "source": [
    "Using Borderline-SMOTE SVM, unlike Borderline-SMOTE, more datapoints are synthesized away from the region of class overlap, such as toward the top left of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60249b4b-b2ef-4d0e-8283-aeb8cff971e2",
   "metadata": {},
   "source": [
    "## Adaptive Synthetic Sampling (ADASYN)\n",
    "Another approach involves generating synthetic samples inversely proportional to the density of the datapoints in the minority class.\n",
    "\n",
    "That is, generate more synthetic datapoints in regions of the feature space where the density of minority datapoints is low, and fewer or none where the density is high.\n",
    "\n",
    "This modification to SMOTE is referred to as the Adaptive Synthetic Sampling Method, or ADASYN, and was proposed to Haibo He, et al. in their 2008 paper named for the method titled “ADASYN: Adaptive Synthetic Sampling Approach For Imbalanced Learning.”\n",
    "\n",
    ">ADASYN is based on the idea of adaptively generating minority data samples according to their distributions: more synthetic data is generated for minority class samples that are harder to learn compared to those minority samples that are easier to learn.\n",
    "\n",
    "— ADASYN: Adaptive synthetic sampling approach for imbalanced learning, 2008.\n",
    "\n",
    "With online Borderline-SMOTE, a discriminative model is not created. Instead, datapoints in the minority class are weighted according to their density, then those datapoints with the lowest density are the focus for the SMOTE synthetic example generation process.\n",
    "\n",
    "The key idea of ADASYN algorithm is to use a density distribution as a criterion to automatically decide the number of synthetic samples that need to be generated for each minority datapoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "281c7bed-55b9-47fe-9b2a-14d0b5f99d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.943\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "y = data[\"target\"]\n",
    "X = data.drop(\"target\", axis=1)\n",
    "ordinal = OrdinalEncoder()\n",
    "X_categorical = ordinal.fit_transform(X.iloc[:,0:3])\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_numerical = imp.fit_transform(X.iloc[:,4:])\n",
    "X_all = np.concatenate((X_categorical, X_numerical), axis=1)\n",
    "\n",
    "# transform the dataset\n",
    "oversample = ADASYN()\n",
    "X_all, y = oversample.fit_resample(X_all, y)\n",
    "\n",
    "# define model and evaluate it\n",
    "model = DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X_all, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedeeb0e-9ea1-4863-9600-396c67e1f4ee",
   "metadata": {},
   "source": [
    "Unlike Borderline-SMOTE, the datapoints that have the most class overlap have the most focus.\n",
    "On problems where these low density datapoints might be outliers, the ADASYN approach may put too much attention on these areas of the feature space, which may result in worse model performance.\n",
    "\n",
    "It may help to remove outliers prior to applying the oversampling procedure, and this might be a helpful heuristic to use more generally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e399fd9-eef1-4110-b126-293ce5439726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
